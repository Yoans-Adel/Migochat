import logging
from typing import Optional, Dict, Any
import json
from Server.config import settings
from app.services.core.base_service import AIService as BaseAIService

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

logger = logging.getLogger(__name__)

class GeminiService(BaseAIService):
    """Gemini AI service for generating responses"""
    
    def __init__(self):
        super().__init__()
        self.api_key = settings.GEMINI_API_KEY
        self.model = None
        self._initialize_model()
        # Initialize the service
        self.initialize()
    
    def _initialize_model(self):
        """Initialize the Gemini model"""
        if not GEMINI_AVAILABLE:
            # Suppress warning on first initialization only
            if not hasattr(self, '_warning_shown'):
                logger.info("Gemini AI service not available - using fallback responses")
                self._warning_shown = True
            self.model = None
            return
            
        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
            logger.info("Gemini model initialized successfully with gemini-2.5-flash")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini model: {e}")
            self.model = None
    
    def generate_response(self, message: str, user_context: Optional[Dict[str, Any]] = None) -> str:
        """
        Generate AI response using Gemini
        
        Args:
            message: User message
            user_context: Additional context about the user
            
        Returns:
            Generated response
        """
        if not GEMINI_AVAILABLE or not self.model:
            logger.warning("Gemini not available, using fallback response")
            return self._fallback_response(message)
        
        try:
            # Build context for the AI
            context = self._build_context(user_context)
            
            # Create prompt optimized for Gemini 2.0 Flash
            prompt = f"""You are Bww-Assistant, a friendly AI shopping assistant for BWW Store - a leading fashion retailer in Egypt specializing in men's, women's, and kids' fashion.

User Context: {context}
User Message: {message}

Guidelines:
â€¢ Match the user's language (Arabic/English) automatically
â€¢ Be conversational, helpful, and enthusiastic about fashion
â€¢ Use emojis naturally (1-2 per response) ğŸ›ï¸ ğŸ‘• ğŸ‘— ğŸ‘Ÿ
â€¢ For product inquiries: Offer to search our catalog
â€¢ For price/availability: Explain we have real-time search
â€¢ Build rapport - ask follow-up questions when relevant
â€¢ Keep responses concise (2-3 sentences max)
â€¢ Professional yet warm tone

Respond naturally:"""
            
            # Generate response
            response = self.model.generate_content(prompt)
            
            if response and response.text:
                logger.info("Gemini 2.0 response generated successfully")
                return response.text.strip()
            else:
                logger.warning("Gemini returned empty response")
                return self._fallback_response(message)
                
        except Exception as e:
            logger.error(f"Error generating Gemini response: {e}")
            return self._fallback_response(message)
    
    def _build_context(self, user_context: Optional[Dict[str, Any]] = None) -> str:
        """Build context string for the AI"""
        if not user_context:
            return "No additional context available"
        
        context_parts = []
        
        if user_context.get('lead_stage'):
            context_parts.append(f"Lead stage: {user_context['lead_stage']}")
        
        if user_context.get('customer_type'):
            context_parts.append(f"Customer type: {user_context['customer_type']}")
        
        if user_context.get('customer_label'):
            context_parts.append(f"Customer label: {user_context['customer_label']}")
        
        if user_context.get('message_count', 0) > 0:
            context_parts.append(f"Previous messages: {user_context['message_count']}")
        
        return "; ".join(context_parts) if context_parts else "New customer"
    
    def _fallback_response(self, message: str) -> str:
        """Fallback response when Gemini is not available"""
        message_lower = message.lower()
        
        # Arabic greetings
        if any(word in message_lower for word in ['Ù…Ø±Ø­Ø¨Ø§', 'Ù‡Ù„Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù…', 'Ø£Ù‡Ù„Ø§', 'ØµØ¨Ø§Ø­', 'Ù…Ø³Ø§Ø¡']):
            return "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! ğŸ‘‹ Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ BWW Store Ø§Ù„Ø°ÙƒÙŠ. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:\n\nğŸ›ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª\nğŸ’° Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø³Ø¹Ø§Ø±\nğŸ“¦ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø§Ù„ØªÙˆØ§ÙØ±\nğŸ“ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ¬Ø±\n\nÙ…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø§Ù„ÙŠÙˆÙ…ØŸ"
        
        # English greetings
        if any(word in message_lower for word in ['hello', 'hi', 'hey', 'good morning', 'good afternoon', 'greetings']):
            return "Hello! ğŸ‘‹ I'm BWW Store's smart assistant. I can help you with:\n\nğŸ›ï¸ Product search\nğŸ’° Prices\nğŸ“¦ Availability\nğŸ“ Store information\n\nWhat can I do for you today?"
        
        # Arabic help requests
        if any(word in message_lower for word in ['Ù…Ø³Ø§Ø¹Ø¯Ø©', 'Ø³Ø§Ø¹Ø¯', 'Ù…Ù…ÙƒÙ†', 'Ø¹Ø§ÙŠØ²', 'Ù…Ø­ØªØ§Ø¬']):
            return "Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯! Ø³Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨ÙƒÙ„ Ø³Ø±ÙˆØ± ğŸ˜Š\n\nÙŠÙ…ÙƒÙ†Ù†ÙŠ:\nâœ¨ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù…Ù†ØªØ¬ ÙÙŠ Ù…ØªØ¬Ø± BWW\nâœ¨ Ø¥Ø¹Ø·Ø§Ø¦Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙˆØ§Ù„Ù…Ù‚Ø§Ø³Ø§Øª\nâœ¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨\n\nÙ…Ø§Ø°Ø§ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ"
        
        # English help requests  
        if any(word in message_lower for word in ['help', 'assist', 'support', 'need', 'want']):
            return "Of course! I'd love to help! ğŸ˜Š\n\nI can:\nâœ¨ Search for any product in BWW Store\nâœ¨ Provide info about prices and sizes\nâœ¨ Help you choose the right product\n\nWhat exactly are you looking for?"
        
        # Arabic product requests
        if any(word in message_lower for word in ['Ù…Ù†ØªØ¬', 'ÙØ³ØªØ§Ù†', 'Ù‚Ù…ÙŠØµ', 'Ø­Ø°Ø§Ø¡', 'Ù…Ù„Ø§Ø¨Ø³', 'Ø¨Ù†Ø·Ù„ÙˆÙ†', 'Ø¬Ø§ÙƒÙŠØª']):
            return "Ø±Ø§Ø¦Ø¹! ğŸ‰ Ø¯Ø¹Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø§ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡.\n\nØ£Ø®Ø¨Ø±Ù†ÙŠ Ø£ÙƒØ«Ø± Ø¹Ù†:\nğŸ“Œ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬\nğŸ“Œ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…ÙØ¶Ù„\nğŸ“Œ Ø§Ù„Ù…Ù‚Ø§Ø³\nğŸ“Œ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©\n\nÙˆØ³Ø£Ø¬Ø¯ Ù„Ùƒ Ø£ÙØ¶Ù„ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª! ğŸ›ï¸"
        
        # English product requests
        if any(word in message_lower for word in ['product', 'dress', 'shirt', 'shoes', 'clothes', 'fashion', 'pants', 'jacket']):
            return "Excellent! ğŸ‰ Let me help you find what you're looking for.\n\nTell me more about:\nğŸ“Œ Product type\nğŸ“Œ Preferred color\nğŸ“Œ Size\nğŸ“Œ Budget\n\nAnd I'll find you the best options! ğŸ›ï¸"
        
        # Price inquiries
        if any(word in message_lower for word in ['Ø³Ø¹Ø±', 'price', 'ÙƒØ§Ù…', 'ÙƒÙ…', 'how much', 'cost', 'ØªÙƒÙ„ÙØ©']):
            return "Ø£Ø³Ø¹Ø§Ø±Ù†Ø§ ØªÙ†Ø§ÙØ³ÙŠØ© Ø¬Ø¯Ø§Ù‹! ğŸ’°\n\nØ£Ø®Ø¨Ø±Ù†ÙŠ Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ² ØªØ¹Ø±Ù Ø³Ø¹Ø±Ù‡ØŒ ÙˆÙ‡Ø¯ÙŠÙƒ ÙƒÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§:\nâ€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ\nâ€¢ Ø£ÙŠ Ø¹Ø±ÙˆØ¶ Ù…ØªØ§Ø­Ø©\nâ€¢ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªÙˆØµÙŠÙ„"
        
        # Thanks
        if any(word in message_lower for word in ['Ø´ÙƒØ±Ø§', 'thank', 'thanks', 'thx']):
            return "Ø§Ù„Ø¹ÙÙˆ! ğŸŒŸ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø§ÙŠÙ…Ø§Ù‹ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ø£ÙŠ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ©ØŒ Ø§Ø¨Ø¹ØªÙ„ÙŠ!"
        
        # Default Arabic response
        if any(ord(char) >= 0x0600 and ord(char) <= 0x06FF for char in message):
            return "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ! ğŸ˜Š\n\nÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ³Ø£Ù„Ù†ÙŠ Ø¹Ù†:\nğŸ” Ù…Ù†ØªØ¬Ø§Øª Ù…Ø¹ÙŠÙ†Ø©\nğŸ’° Ø§Ù„Ø£Ø³Ø¹Ø§Ø±\nğŸ“¦ Ø§Ù„ØªÙˆØ§ÙØ±\nğŸšš Ø§Ù„ØªÙˆØµÙŠÙ„\n\nØ§ÙƒØªØ¨ Ù„ÙŠ Ø§Ù„Ù„ÙŠ Ù…Ø­ØªØ§Ø¬Ù‡ ÙˆØ£Ù†Ø§ Ù‡Ø³Ø§Ø¹Ø¯Ùƒ ÙÙˆØ±Ø§Ù‹!"
        
        # Default English response
        return "I'm here to help! ğŸ˜Š\n\nYou can ask me about:\nğŸ” Specific products\nğŸ’° Prices\nğŸ“¦ Availability\nğŸšš Delivery\n\nJust tell me what you need!"
    
    def is_available(self) -> bool:
        """Check if Gemini service is available"""
        return GEMINI_AVAILABLE and self.model is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about the current model"""
        return {
            "service": "Gemini",
            "model": "gemini-2.5-flash",
            "available": self.is_available(),
            "api_key_configured": bool(self.api_key),
            "package_installed": GEMINI_AVAILABLE
        }
    
    def _do_initialize(self):
        """Initialize Gemini service"""
        self._initialize_model()
    
    def _generate_response_impl(self, query: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """AI-specific response generation"""
        try:
            response = self.generate_response(query)
            return {
                "response": response,
                "success": True,
                "model_used": "gemini" if self.is_available() else "fallback"
            }
        except Exception as e:
            self.logger.error(f"Error generating Gemini response: {e}")
            return {
                "response": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
                "success": False,
                "error": str(e),
                "model_used": "fallback"
            }
